{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586051eb-562e-49c0-bc8f-ada502d199a0",
   "metadata": {},
   "source": [
    "# <b style=\"color:green\">Text Representation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56e45b5-19c1-40de-8892-fc9bcb2fa5fe",
   "metadata": {},
   "source": [
    "- How to convert a text to number.\n",
    "- Feature Extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f3e5cb-cdad-4088-9772-19ae9ce94ad6",
   "metadata": {},
   "source": [
    "## <b style=\"color:red\">Introductions</b>\n",
    "- What is Feature Extraction from text?\n",
    "  - To convert text into numbers is called `Feature Extraction` or `Text Representation` or `Text Vectorization`. Because machine only understand numbers not words.\n",
    "- Why is it difficult?\n",
    "  - It is easy to convert a image to numbers.\n",
    "  - It is easy to convert a speech to numbers.\n",
    "  - It is not easy to convert to convert a sentence to number. Because meaning of sentence will change.\n",
    "- What are the techniques to convert a text to numbers?\n",
    "  - OHE : One Hot Encoding\n",
    "  - Bag of words\n",
    "  - N-Grams\n",
    "  - TF-IDF\n",
    "  - Custome Features : Make your own features\n",
    "  - Word2Vec : embeddings (DL Topics)\n",
    "- Common Terms\n",
    "  - _Corpus (C)_ : Add all words of dataset including repeated words is called Corpus. Means Combination of all words of sentence.\n",
    "  - _Vocabulary (V)_ : Get all uniques words of Corpus is called Vocabulary.\n",
    "  - _Document (D)_ : Indivisual text-document of single row is called Document.\n",
    "  - _Word (W)_ : Indivisual word of Document is called Word.\n",
    "  - __Example__:\n",
    "    - Dataset\n",
    "      <pre>\n",
    "      _____________________________\n",
    "      |D1 | people watch campusx  |\n",
    "      |___|_______________________|\n",
    "      |D2 | campusx watch campusx |\n",
    "      |___|_______________________|\n",
    "      |D3 | people write comment  |\n",
    "      |___|_______________________|\n",
    "      |D4 | campusx write comment |\n",
    "      |___|_______________________|\n",
    "  </pre>\n",
    "    - _Corpus_ : people watch campusx campusx watch campusx people write comment campusx write comment\n",
    "    - _Vocabulary_ : people watch campusx write comment  : V=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79330dd6-cd9d-419c-90ee-074c2d21ac0a",
   "metadata": {},
   "source": [
    "### <b style=\"color:red\">One Hot Encoding (OHE)</b>\n",
    "- Dataset\n",
    "  <pre>\n",
    "      _____________________________\n",
    "      |D1 | people watch campusx  |\n",
    "      |___|_______________________|\n",
    "      |D2 | campusx watch campusx |\n",
    "      |___|_______________________|\n",
    "      |D3 | people write comment  |\n",
    "      |___|_______________________|\n",
    "      |D4 | campusx write comment |\n",
    "      |___|_______________________|\n",
    "  </pre>\n",
    "  - _Corpus_ : people watch campusx campusx watch campusx people write comment campusx write comment\n",
    "  - _Vocabulary_ : people watch campusx write comment  : V=5\n",
    "- One Hot Encoding says that convert all words of your Documents into a `V` dimensional vector.\n",
    "  <pre>\n",
    "    ____________________________________________ \n",
    "    |       |people|watch|campusx|write|comment|\n",
    "    |_______|______|_____|_______|_____|_______|\n",
    "    |people |   1  |  0  |   0   |  0  |   0   |\n",
    "    |_______|______|_____|_______|_____|_______|\n",
    "    |watch  |   0  |  1  |   0   |  0  |   0   |\n",
    "    |_______|______|_____|_______|_____|_______|\n",
    "    |campux |   0  |  0  |   1   |  0  |   0   |\n",
    "    |_______|______|_____|_______|_____|_______|\n",
    "    |write  |   0  |  0  |   0   |  1  |   0   |\n",
    "    |_______|______|_____|_______|_____|_______|\n",
    "    |comment|   0  |  0  |   0   |  0  |   1   |\n",
    "    |_______|______|_____|_______|_____|_______|\n",
    "  </pre>\n",
    "- One Hot Encoding\n",
    "  <pre>\n",
    "      D1 = [[1, 0, 0, 0, 0],\n",
    "            [0, 1, 0, 0, 0],\n",
    "            [0, 0, 1, 0, 0]]\n",
    "      D2 = [[0, 0, 1, 0, 0],\n",
    "            [0, 1, 0, 0, 0],\n",
    "            [0, 0, 1, 0, 0]]\n",
    "      D3 = [[1, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 1, 0],\n",
    "            [0, 0, 0, 0, 1]]\n",
    "      D4 = [[0, 0, 1, 0, 0],\n",
    "            [0, 0, 0, 1, 0],\n",
    "            [0, 0, 0, 0, 1]]\n",
    "  </pre> \n",
    "- Advantage\n",
    "  - It is intevtive.\n",
    "  - It is easy to implement.\n",
    "- Disadvantage\n",
    "  - Sparsity (Identity array) : Overfitting\n",
    "  - Different length of array\n",
    "  - OOV(Out of Vocabulary) : New word come can not handle.\n",
    "  - No capturing of semantic meaning. eg. : walk, run, bottle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984a86b-4000-4540-b477-db52df3748e1",
   "metadata": {},
   "source": [
    "### <b style=\"color:red\">Bag of Words</b>\n",
    "- Use for Text Classification Problems.\n",
    "- Depends upon how many times word come in sentence.\n",
    "- In Bag of Words, Order of words does not matter.\n",
    "- Dataset\n",
    "  - <pre>\n",
    "      ___________________________________\n",
    "      |D1 | people watch campusx  |  1  |\n",
    "      |___|_______________________|_____|\n",
    "      |D2 | campusx watch campusx |  1  |\n",
    "      |___|_______________________|_____| \n",
    "      |D3 | people write comment  |  0  |\n",
    "      |___|_______________________|_____|\n",
    "      |D4 | campusx write comment |  0  |\n",
    "      |___|_______________________|_____|\n",
    "  </pre>\n",
    "  - _Corpus_ : people watch campusx campusx watch campusx people write comment campusx write comment\n",
    "  - _Vocabulary_ : people watch campusx write comment  : V=5\n",
    "- Bag of words says that how many times word occures in a Document.\n",
    "  <pre>\n",
    "    ____________________________________________ \n",
    "    |       |people|watch|campusx|write|comment|\n",
    "    |_______|______|_____|_______|_____|_______|\n",
    "    |  D1   |   1  |  1  |   1   |  0  |   0   |\n",
    "    |_______|______|_____|_______|_____|_______|\n",
    "    |  D2   |   0  |  1  |   2   |  0  |   0   |\n",
    "    |_______|______|_____|_______|_____|_______|\n",
    "    |  D3   |   1  |  0  |   0   |  1  |   1   |\n",
    "    |_______|______|_____|_______|_____|_______|\n",
    "    |  D4   |   0  |  0  |   1   |  1  |   1   |\n",
    "    |_______|______|_____|_______|_____|_______|\n",
    "  </pre>\n",
    "- Every _Document_ convert into ___V___ dimensional vector. \\\n",
    "  Words are related to each other in a vector plane. The `cos(theta)` will tell how close two words are related \\\n",
    "  to each other. Value of `theta` is high low related, value of `theta` is low high related. \\\n",
    "  For this we use a library `from sklearn.feature_extraction.text import CountVectorizer`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64fd6cc1-7d69-46ca-aaed-2567e03c2213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "docs = ['people watch campusx',\n",
    "       'campusx watch campusx',\n",
    "       'people write comment',\n",
    "       'campusx write comment']\n",
    "output = [1, 1, 0, 0]\n",
    "\n",
    "df = pd.DataFrame({'text':docs, 'output':output})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fd09f7-b7c8-44f9-9549-fdac755704c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a62b4c7e-88c4-438b-ba0e-e8fa97ff0697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "bow = cv.fit_transform(df['text'])\n",
    "# vocab\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eee7063-7501-4f3d-a0f1-e1d32e5a2bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0]]\n",
      "[[2 0 0 1 0]]\n",
      "[[0 1 1 0 1]]\n",
      "[[1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# [   0   ,    1   ,   2   ,  3   ,  4   ]\n",
    "# [campusx, comment, people, watch, write]\n",
    "\n",
    "print(bow[0].toarray())\n",
    "print(bow[1].toarray())\n",
    "print(bow[2].toarray())\n",
    "print(bow[3].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1794c52-3cf5-456c-808a-b608b7dc6e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 2, 2, 1]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of vocabulary problem not occure\n",
    "cv.transform(['campusx watch and write comment of people because people watch campusx']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3afdf8c3-6251-467c-a590-9f444ad839b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 2, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = [\"people and student watch movies and write comment. campusx is youtube channel. from where people can learn manythings.\"]\n",
    "cv.transform(msg).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef9927-9e78-4437-a167-578f0593f819",
   "metadata": {},
   "source": [
    "- `from sklearn.feature_extraction.text import CountVectorizer` \\\n",
    "   `cv = CountVectorizer()`\n",
    "- lowercase=True, tokenizer=None, stop_words=None, token_pattern='(?u)\\b\\w\\w+\\b'   \\\n",
    "  ngram_range=(1, 1), binary=False/True (n>1 => 1), max_feature=1 (select only 1 feature whoes frequency high)  \\\n",
    "  max_feature=2 (select only 2 feature whoes frequecy high)\n",
    "- Advantage :\n",
    "  - Simple and intuitive\n",
    "  - Different length of array acceptable always get fixed size of output\n",
    "  - No problem of OOV(Out of Vocabulary)\n",
    "  - Capture semantic relationship\n",
    "- Disadvantage :\n",
    "  - Sparsity : Overfitting\n",
    "  - Ignore OOV(Out of Vocabulary) word. Information missing.\n",
    "  - No consider order of words in a sentence.\n",
    "  - * This is a very good movie.\n",
    "    * This is not a very good movie.\n",
    "    * Both sentence are opposite to each other. But `Bag of Word` think the are more close to each other.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237e47e2-4311-499d-bb49-e0d726e39a34",
   "metadata": {},
   "source": [
    "### <b style=\"color:red\">N-grams or Bag of N-grams</b>\n",
    "- Rather than taking single word of Vocabulary in `Bag of Words`. Take multiple words to make Vocabulary in `N-grams`.\n",
    "- Bi-grams : Take 2 contiguous words to make Vocabulary. \\\n",
    "  Tri-grams : Take 3 contiguous words to make Vocabulary. \\\n",
    "  n-grams : Take n contiguous words to make Vocabulary.\n",
    "- Dataset\n",
    "  - <pre>\n",
    "      ___________________________________\n",
    "      |D1 | people watch campusx  |  1  |\n",
    "      |___|_______________________|_____|\n",
    "      |D2 | campusx watch campusx |  1  |\n",
    "      |___|_______________________|_____| \n",
    "      |D3 | people write comment  |  0  |\n",
    "      |___|_______________________|_____|\n",
    "      |D4 | campusx write comment |  0  |\n",
    "      |___|_______________________|_____|\n",
    "  </pre>\n",
    "- Bag of ___Bi-grams___. \\\n",
    "  Vocabulary : | people watch | watch campusx | campusx watch | people write | write comment |campusx write | \\\n",
    "  __V__ = 6\n",
    "  <pre>\n",
    "    ___________________________________________________________________________________________\n",
    "    |       |people watch|watch campusx|campusx watch|people write|write comment|campusx write|\n",
    "    |_______|____________|_____________|_____________|____________|_____________|_____________|\n",
    "    |  D1   |      1     |      1      |      0      |      0     |      0      |      0      |\n",
    "    |_______|____________|_____________|_____________|____________|_____________|_____________|\n",
    "    |  D2   |      0     |      1      |      1      |      0     |      0      |      0      |\n",
    "    |_______|____________|_____________|_____________|____________|_____________|_____________|\n",
    "    |  D3   |      0     |      0      |      0      |      1     |      1      |      0      |\n",
    "    |_______|____________|_____________|_____________|____________|_____________|_____________|\n",
    "    |  D4   |      0     |      0      |      0      |      0     |      1      |      1      |\n",
    "    |_______|____________|_____________|_____________|____________|_____________|_____________|\n",
    "  </pre>\n",
    "- Bag of ___Tri-grams___. \\\n",
    "  Vocabulary : | people watch campusx | campusx watch campusx | people write comment | campusx write comment | \\\n",
    "  __V__ = 4\n",
    "  <pre>\n",
    "    _______________________________________________________________________________________________\n",
    "    |       |people watch campusx|campusx watch campusx|people write comment|campusx write comment|\n",
    "    |_______|____________________|_____________________|____________________|_____________________|\n",
    "    |  D1   |          1         |          0          |          0         |          0          |\n",
    "    |_______|____________________|_____________________|____________________|_____________________|\n",
    "    |  D2   |          0         |          1          |          0         |          0          |\n",
    "    |_______|____________________|_____________________|____________________|_____________________|\n",
    "    |  D3   |          0         |          0          |          1         |          0          |\n",
    "    |_______|____________________|_____________________|____________________|_____________________|\n",
    "    |  D4   |          0         |          0          |          0         |          1          |\n",
    "    |_______|____________________|_____________________|____________________|_____________________|\n",
    "  </pre>\n",
    "\n",
    "- `from sklearn.feature_extraction.text import CountVectorizer`  \\\n",
    "  `cv = CountVectorizer(ngram_range=(1, 1)) # Uni-grams or Bag of words` \\\n",
    "  `cv = CountVectorizer(ngram_range=(2, 2)) # Bi-grams` \\\n",
    "  `cv = CountVectorizer(ngram_range=(1, 2)) # Uni-grams + Bi-grams` \\\n",
    "  `cv = CountVectorizer(ngram_range=(3, 3)) # Tri-grams` \\\n",
    "  `cv = CountVectorizer(ngram_range=(2, 3)) # Bi-grams + Tri-grams` \\\n",
    "  `cv = CountVectorizer(ngram_range=(1, 3)) # Uni-grams + Bi-grams + Tri-grams`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53395c48-d7ad-43f8-a870-8ed5c96ac1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "docs = ['people watch campusx',\n",
    "       'campusx watch campusx',\n",
    "       'people write comment',\n",
    "       'campusx write comment']\n",
    "output = [1, 1, 0, 0]\n",
    "\n",
    "df = pd.DataFrame({'text':docs, 'output':output})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71510595-ddc0-4e0b-b6b7-976ae4f04bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f06f086-9023-46d6-8b81-7c2b880787a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "# Uni-grams\n",
    "cv = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = cv.fit_transform(df['text'])\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6632482-4f82-4e4d-a0ef-ba04913cbb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people watch': 2, 'watch campusx': 4, 'campusx watch': 0, 'people write': 3, 'write comment': 5, 'campusx write': 1}\n"
     ]
    }
   ],
   "source": [
    "# Bi-grams\n",
    "cv = CountVectorizer(ngram_range=(2, 2))\n",
    "bow = cv.fit_transform(df['text'])\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2971901d-1a85-4fad-96d8-247c05e10eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 4, 'watch': 7, 'campusx': 0, 'people watch': 5, 'watch campusx': 8, 'campusx watch': 1, 'write': 9, 'comment': 3, 'people write': 6, 'write comment': 10, 'campusx write': 2}\n"
     ]
    }
   ],
   "source": [
    "# Uni-grams + Bi-grams\n",
    "cv = CountVectorizer(ngram_range=(1, 2))\n",
    "bow = cv.fit_transform(df['text'])\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02fbc256-45fe-45a9-85a9-f6a34471fc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people watch campusx': 2, 'campusx watch campusx': 0, 'people write comment': 3, 'campusx write comment': 1}\n"
     ]
    }
   ],
   "source": [
    "# Tri-grams\n",
    "cv = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = cv.fit_transform(df['text'])\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91a4e1c2-ef89-456b-8fa8-157bcb19e705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people watch': 4, 'watch campusx': 8, 'people watch campusx': 5, 'campusx watch': 0, 'campusx watch campusx': 1, 'people write': 6, 'write comment': 9, 'people write comment': 7, 'campusx write': 2, 'campusx write comment': 3}\n"
     ]
    }
   ],
   "source": [
    "# Bi-grams + Tri-grams\n",
    "cv = CountVectorizer(ngram_range=(2, 3))\n",
    "bow = cv.fit_transform(df['text'])\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3413a16b-346f-4ac6-913e-aa026e7768a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 6, 'watch': 11, 'campusx': 0, 'people watch': 7, 'watch campusx': 12, 'people watch campusx': 8, 'campusx watch': 1, 'campusx watch campusx': 2, 'write': 13, 'comment': 5, 'people write': 9, 'write comment': 14, 'people write comment': 10, 'campusx write': 3, 'campusx write comment': 4}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Uni-grams + Bi-grams + Tri-grams\n",
    "cv = CountVectorizer(ngram_range=(1, 3))\n",
    "bow = cv.fit_transform(df['text'])\n",
    "print(cv.vocabulary_)\n",
    "print(len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b03399-a8ce-4be5-b847-cf582647c269",
   "metadata": {},
   "source": [
    "- Dataset ; \\\n",
    "  D1 : This movie is very good. \\\n",
    "  D2 : This movie is not good.\n",
    "- Uni-grams :    \n",
    "  <pre>\n",
    "                   _________________________________________\n",
    "      Vocabulary = | This | movie | is | very | good | not |       V=6\n",
    "                   |______|_______|____|______|______|_____|\n",
    "                D1 |  1   |   1   |  1 |  1   |  1   |  0  |  \n",
    "                   |______|_______|____|______|______|_____|\n",
    "                D2 |  1   |   1   |  1 |  0   |  1   |  1  |\n",
    "                   |______|_______|____|______|______|_____|\n",
    "                Similar  = 4\n",
    "                Different = 2\n",
    "                Both Vector are much closer to each other.\n",
    "  </pre>\n",
    "- Bi-grams :    \n",
    "  <pre>\n",
    "                   ___________________________________________________________________\n",
    "      Vocabulary = | This movie | movie is | is very | very good | is not | not good |      V=6\n",
    "                   |____________|__________|_________|___________|________|__________|\n",
    "                D1 |      1     |     1    |    1    |      1    |    0   |     0    |  \n",
    "                   |____________|__________|_________|___________|________|__________|\n",
    "                D2 |      1     |     1    |    0    |      0    |    1   |     1    |\n",
    "                   |____________|__________|_________|___________|________|__________|\n",
    "                Similar  = 2\n",
    "                Different = 4\n",
    "                Both Vector are not close to each other.\n",
    "  </pre>\n",
    "\n",
    "- Advantage :\n",
    "  - Able to capture semantic meaning of sentence.\n",
    "  - Easy to implement\n",
    "  - Intiutive to understand\n",
    "- Disadvantage :\n",
    "  - n-grams < (n+1)-grams => More complex model, More computation.\n",
    "  - No solution for new word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d324bd7-1037-4eac-bf04-825c6e6aece1",
   "metadata": {},
   "source": [
    "### <b style=\"color:red\">TF-IDF</b>\n",
    "- It assign different weightage to different word of Docuement. If fequence of a word in a Document is high. But low in Corpus. Then that word get more weightage for that Document comparision than other words.\n",
    "- `TF : Term Frequency`  \\\n",
    "  `IDF : Inverse Document Frequency`   \\\n",
    "  `Weightage of Word = TF x IDF`\n",
    "-\n",
    "  <pre>\n",
    "                 (Number of occurrences of term <b><i>t</i></b> in document <b><i>d</i></b>)\n",
    " TF(t, d) =  _______________________________________________________________\n",
    "                    (Total number of terms in the document <b><i>d</i></b>)\n",
    "\n",
    "                    (Total number of documents in the corpus)\n",
    " IDF(t) =  log<sub>e</sub>_________________________________________________________ + 1\n",
    "                    (Number of documents with term <b><i>t</i></b> in them)\n",
    "\n",
    "  </pre>\n",
    "- Dataset\n",
    "  - <pre>\n",
    "      ___________________________________\n",
    "      |D1 | people watch campusx  |  1  |\n",
    "      |___|_______________________|_____|\n",
    "      |D2 | campusx watch campusx |  1  |\n",
    "      |___|_______________________|_____| \n",
    "      |D3 | people write comment  |  0  |\n",
    "      |___|_______________________|_____|\n",
    "      |D4 | campusx write comment |  0  |\n",
    "      |___|_______________________|_____|\n",
    "  </pre>\n",
    "  - TF(people, D1) = 1/3   \\\n",
    "    TF(campusx, D2) = 2/3  \\\n",
    "    Term frequency is like __probability__ of that word in Document. Which will be in range of [0, 1]\n",
    "  - __log<sub>e</sub>__ is also called `ln`. \\\n",
    "    IDF(campusx) = ln(4/3)+1 = 1.28  \\\n",
    "    IDF(watch) = ln(4/2)+1 = 1.69    \\\n",
    "    IDF(people) = ln(4/2)+1 = 1.69   \\\n",
    "    IDF(write) = ln(4/2)+1 = 1.69    \\\n",
    "    IDF(comment) = ln(4/2)+1 = 1.69  \\\n",
    "  - What if IDF(word) = ln(4/4)+1 = 1  : __coz ln(1)=0__  \\\n",
    "    What if IDF(word) = ln(1000/1)+1 = 7.90 : __Reason to take ln.__\n",
    "  - `Weightage of Word = TF x IDF`\n",
    "  <pre>\n",
    "      ___________________________________________________________________________________\n",
    "      |      |    people    |     watch    |   campusx    |   write      |   comment    |\n",
    "      |______|______________|______________|______________|______________|______________|\n",
    "      |  D1  | (1/3)*(1.69) | (1/3)*(1.69) | (1/3)*(1.28) | (0)*(1.69)   | (0)*(1.69)   |\n",
    "      |______|______________|______________|______________|______________|______________|\n",
    "      |  D2  | (0)*(1.69)   | (1/3)*(1.69) | (2/3)*(1.28) | (0)*(1.69)   | (0)*(1.69)   |\n",
    "      |______|______________|______________|______________|______________|______________|\n",
    "      |  D3  | (1/3)*(1.69) | (0)*(1.69)   | (0)*(1.28)   | (1/3)*(1.69) | (1/3)*(1.69) |\n",
    "      |______|______________|______________|______________|______________|______________|\n",
    "      |  D4  | (0)*(1.69)   | (0)*(1.69)   | (1/3)*(1.28) | (1/3)*(1.69) | (1/3)*(1.69) |\n",
    "      |______|______________|______________|______________|______________|______________|\n",
    "  </pre>\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e7fda06-bec9-4110-a562-1bf996a54055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "docs = ['people watch campusx',\n",
    "       'campusx watch campusx',\n",
    "       'people write comment',\n",
    "       'campusx write comment']\n",
    "output = [1, 1, 0, 0]\n",
    "\n",
    "df = pd.DataFrame({'text':docs, 'output':output})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6749164-75c7-4d63-8a66-804b26994423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49681612, 0.        , 0.61366674, 0.61366674, 0.        ],\n",
       "       [0.8508161 , 0.        , 0.        , 0.52546357, 0.        ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.57735027],\n",
       "       [0.49681612, 0.61366674, 0.        , 0.        , 0.61366674]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5b9b03a-a86a-4abb-afd6-ade412c79ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22314355 1.51082562 1.51082562 1.51082562 1.51082562]\n",
      "['campusx' 'comment' 'people' 'watch' 'write']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.idf_)\n",
    "print(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f721a-eaa0-4197-a0bb-c168ad44b192",
   "metadata": {},
   "source": [
    "- Advantage :\n",
    "  - Use more in IRS(Information Retrival System) like search engine.\n",
    "- Disadvantage :\n",
    "  - Sparsity\n",
    "  - OOV (Out of Vocabulary)\n",
    "  - Dimension will be big. Overfitting may occures.\n",
    "  - Can not capture semantic meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7011bf-4309-4acd-9611-1fbd676e4cbd",
   "metadata": {},
   "source": [
    "### <b style=\"color:red\">Custom Features</b>\n",
    "- Number of positive words. \\\n",
    "  Number of negative words. \\\n",
    "  Ratio of positive/negative words \\\n",
    "  Word count. \\\n",
    "  Character count \n",
    "- Features\n",
    "  1. Techniques Features\n",
    "  2. Custome Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb06a34-6a1f-45d6-8f6b-0358b9ca79b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
