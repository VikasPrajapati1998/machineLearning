{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1e794d-c4b5-43c9-83dd-0064668f2e82",
   "metadata": {},
   "source": [
    "## <b style=\"color:green\">Text Classification</b>\n",
    "- **Text Classification of Two Type**\n",
    "  - ___ML : Machine Learning___\n",
    "  - ___DL : Deep Learning___\n",
    "- Pipe Line of Text Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18c9437-bcf4-4741-ac1c-a8201b16fb84",
   "metadata": {},
   "source": [
    "- __Classification__ : Some specific output.\n",
    "- Type of Classification\n",
    "  - Binary Classification : Two possible output\n",
    "  - Multi-class Classification : Multiple possible output\n",
    "  - Multi-Level Classification : For one input, multiple possible output\n",
    "- __Application__ :    \n",
    "  1. Email Classification = Spam or Not Spam    \n",
    "  2. Email Classification = Sales or Support     \n",
    "  3. Customer Support Chatbot                    \n",
    "  4. Sentiment Analysis = Happy, Sad, Normal\n",
    "  5. Language Detection and Translation\n",
    "  6. Fake News Detection\n",
    "- __Pipeline__ :\n",
    "  <pre>\n",
    "                         __________________________\n",
    "                        |    Data Acquisation      |\n",
    "                        |__________________________|\n",
    "                                     |\n",
    "                                    \\|/\n",
    "                                     '\n",
    "                         __________________________\n",
    "                        |   Text Preprocessing     |\n",
    "                        |__________________________|\n",
    "                                     |\n",
    "                                    \\|/\n",
    "                                     '\n",
    "                         __________________________\n",
    "                        |  Text Vectorization      |\n",
    "                        |__________________________|\n",
    "                                     |\n",
    "                                    \\|/\n",
    "                                     '\n",
    "                         __________________________\n",
    "                        |        Modelling         |   ML: Navie Bayes, Random Forest\n",
    "                        |__________________________|   DL: RNN->LSTM, CNN, BERT\n",
    "                                     |\n",
    "                                    \\|/\n",
    "                                     '\n",
    "                         __________________________\n",
    "                        |        Evaluvation       |  Matrix: Accuracy Score, Precision and Recall\n",
    "                        |__________________________|          Confusion Matrix, ROC or AUC Curve\n",
    "                                     |\n",
    "                                    \\|/\n",
    "                                     '\n",
    "                         __________________________\n",
    "                        |         Delploy          |\n",
    "                        |__________________________|\n",
    "\n",
    "\n",
    "  </pre>\n",
    "\n",
    "- Different Approaches :\n",
    "  1. Heuristic Approaches\n",
    "  2. Using API Approaches\n",
    "  3. Using ML Apporaches = BOW, ngrams,TF-IDF, Navie Baise, RF, SVM\n",
    "  4. Using DL Approaches = RNN(LSTM), CNN, BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18810b0-47a7-449d-b22a-184b4445d966",
   "metadata": {},
   "source": [
    "### **1. Heuristic Approaches**\n",
    "- Use when you don't have sufficient data.\n",
    "\n",
    "### **2. Using API**\n",
    "- Use ready made API : Application Programming Interface\n",
    "- Some APIs : AWS, GCP, NLP Cloud\n",
    "\n",
    "### **3. Using BoW, n-grams and TF-IDF**\n",
    "- Bag of Words\n",
    "- <pre>\n",
    "                                     _______ Naive Bayes   \\\n",
    "                                    /                       \\\n",
    "                                   /                         \\\n",
    "     Text                         /                           \\  Compare Both Result\n",
    "    Preprocessing >---> BoW >--->                             /\n",
    "                      n-gram      \\                          /\n",
    "                      TF-IDF       \\                        /\n",
    "                                    \\_______ Random Forest /\n",
    "  </pre>\n",
    "\n",
    "### **4. Use Word2Vec**\n",
    "- 1. Use Pre-trained Word2Vec\n",
    "  2. Train Your Word2Vec on Your Data (Make sure you have sufficient data)\n",
    "- Sentence >---> `avg word2vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2254e1-4e6e-4adb-9628-ccbf1fdd3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e94943-4160-4dd2-95b3-5ff0138af460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.read_csv(\"../data/IMDB_Dataset.csv\")\n",
    "df = temp_df.iloc[:10000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8c92da3-4c8a-4e49-a97b-878615ded883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb2add62-8aed-4e59-817d-adc11de91ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad962fff-beab-456a-9b65-f1002bbbfbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    5028\n",
       "negative    4972\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No class imbalance. \n",
    "# ratio of classes should be equal, else highter will dominate.\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "414e7179-a297-49b4-b643-12da4ba9e3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5331486-0750-4738-9fe6-bdec16d5a702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicated review (rows)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbf3b05e-b281-40fd-a659-cb18085d56b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Local\\Temp\\ipykernel_8292\\304969660.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop_duplicates(inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop drop duplicated review\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b663f999-6724-4fec-942e-7b0aa87cd038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Preprocessing\n",
    "# 1. Remove tags\n",
    "# 2. Lowercase\n",
    "# 3. Remove Punctuations\n",
    "# 4. Remove stopwords\n",
    "# 5. Spelling correct\n",
    "# 6. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "708a88f2-6d8f-4800-ac3b-1c0b3271a328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Local\\Temp\\ipykernel_8292\\909089613.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].apply(remove_tags)\n"
     ]
    }
   ],
   "source": [
    "# remove tags\n",
    "import re\n",
    "\n",
    "def remove_tags(text):\n",
    "    pattern = re.sub(re.compile('<.*?>'), '', text)\n",
    "    return pattern\n",
    "\n",
    "df['review'] = df['review'].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919cf517-c480-4b39-9d5c-64ab34e0ad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Local\\Temp\\ipykernel_8292\\2917764948.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# lowercasing\n",
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10241c30-1fbc-43d4-a23f-3e286dfee8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Local\\Temp\\ipykernel_8292\\4065602087.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].apply(remove_url)\n"
     ]
    }
   ],
   "source": [
    "# remove url\n",
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)\n",
    "\n",
    "df['review'] = df['review'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a222e7da-ee5a-4c84-9158-2fa35ab0ee23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Local\\Temp\\ipykernel_8292\\3180427501.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].apply(remove_punc)\n"
     ]
    }
   ],
   "source": [
    "# remove punctuations\n",
    "import string, time\n",
    "\n",
    "exclude = string.punctuation\n",
    "\n",
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('', '', exclude))\n",
    "\n",
    "df['review'] = df['review'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29fd0509-f485-4504-ad76-15887d0bca51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\kumar\\AppData\\Local\\Temp\\ipykernel_8292\\3825213897.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].apply(remove_stopwords)\n"
     ]
    }
   ],
   "source": [
    "# remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word in sw:\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "df['review'] = df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2ef3679-06d3-4e54-975a-3950a20c21fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one    reviewers  mentioned   watching  1 oz e...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production  filming techniqu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought    wonderful way  spend time    hot s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres  family   little boy jake thi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love   time  money   visually s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>fun entertaining movie  wwii german spy julie ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>give   break   anyone say     good hockey movi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>movie   bad movie   watching  endless series ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>movie   probably made  entertain  middle sc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>smashing film  filmmaking shows  intense  stra...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9983 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment\n",
       "0     one    reviewers  mentioned   watching  1 oz e...  positive\n",
       "1      wonderful little production  filming techniqu...  positive\n",
       "2      thought    wonderful way  spend time    hot s...  positive\n",
       "3     basically theres  family   little boy jake thi...  negative\n",
       "4     petter matteis love   time  money   visually s...  positive\n",
       "...                                                 ...       ...\n",
       "9995  fun entertaining movie  wwii german spy julie ...  positive\n",
       "9996  give   break   anyone say     good hockey movi...  negative\n",
       "9997   movie   bad movie   watching  endless series ...  negative\n",
       "9998     movie   probably made  entertain  middle sc...  negative\n",
       "9999  smashing film  filmmaking shows  intense  stra...  positive\n",
       "\n",
       "[9983 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "033800fd-1bfd-4e57-a3bf-fb7484d9df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0669b7af-ff87-4837-bad8-a3201fdfef3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9983"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story=[]\n",
    "for doc in df['review']:\n",
    "    raw_sent = sent_tokenize(doc)\n",
    "    for sent in raw_sent:\n",
    "        story.append(simple_preprocess(sent))\n",
    "\n",
    "len(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a8eec7d-4b1e-4afc-9f4b-beaca3781e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(\n",
    "    vector_size=100, # size of vector\n",
    "    window=10,  # size of window 10 left and 10 right\n",
    "    min_count=2,\n",
    "    sg=0, # sg=0 for CBOW, and sg=1 for Skip-gram\n",
    "    workers=4   # depend upon number of cores of CPU.\n",
    ")\n",
    "\n",
    "model.build_vocab(story)  # built vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4238fae-faa1-4310-96a4-4daa5de21e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5473051, 5901340)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(story, total_examples=model.corpus_count, epochs=5)  # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e43ea6e-efe3-4b35-ab9f-14cb44ef81b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie',\n",
       " 'film',\n",
       " 'one',\n",
       " 'like',\n",
       " 'good',\n",
       " 'would',\n",
       " 'even',\n",
       " 'time',\n",
       " 'see',\n",
       " 'really']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index_to_key[:10] # words in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "864731a0-ab60-4700-a4fe-e48def90ec3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35178"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key) # total number of words in my vocab"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18bcb73b-2166-4e90-9eee-a3339fcad6d9",
   "metadata": {},
   "source": [
    "# code\n",
    "lst = [[1, 2, 3, 4], \n",
    "       [2, 4, 6, 8], \n",
    "       [3, 6, 9, 12]]\n",
    "\n",
    "print(np.mean(lst, axis=0), len(np.mean(lst, axis=0)))\n",
    "print(np.mean(lst, axis=1), len(np.mean(lst, axis=1)))\n",
    "\n",
    "# output\n",
    "[2. 4. 6. 8.] 4\n",
    "[2.5 5.  7.5] 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17fb2cff-9bb5-42ea-8d66-8d48a7ca5af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take vector of reviews\n",
    "# avg word2vec\n",
    "def document_vector(doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc.split() if word in model.wv.index_to_key]\n",
    "    return np.mean(model.wv[doc], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26702393-6d78-4157-8549-abc0c0d43fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wonderful little production  filming technique   unassuming  oldtimebbc fashion  gives  comforting  sometimes discomforting sense  realism   entire piece  actors  extremely well chosen michael sheen    got   polari      voices  pat    truly see  seamless editing guided   references  williams diary entries     well worth  watching     terrificly written  performed piece  masterful production  one   great masters  comedy   life  realism really comes home   little things  fantasy   guard  rather  use  traditional dream techniques remains solid  disappears  plays   knowledge   senses particularly   scenes concerning orton  halliwell   sets particularly   flat  halliwells murals decorating every surface  terribly well done\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.10056741,  0.500713  , -0.02323362, -0.06268851,  0.42575073,\n",
       "       -0.5155354 ,  0.0740856 ,  0.9545436 , -0.48486236, -0.2051599 ,\n",
       "       -0.4923306 , -0.6216524 , -0.45308116,  0.18248796, -0.0086668 ,\n",
       "       -0.18265867,  0.47713113, -0.38996923,  0.06732437, -0.9352394 ,\n",
       "        0.2911005 ,  0.20937777,  0.4047525 , -0.4085607 , -0.1658181 ,\n",
       "        0.09734292, -0.38950437,  0.0260168 , -0.36889794, -0.2681664 ,\n",
       "        0.57684696,  0.0527646 ,  0.16884053, -0.2784094 , -0.23969743,\n",
       "        0.51930237,  0.21116062, -0.27525136, -0.23851438, -0.5033268 ,\n",
       "        0.24341816, -0.4221202 , -0.1757259 ,  0.16313827,  0.18518403,\n",
       "       -0.32732207, -0.29724208, -0.04568945,  0.18549344,  0.6316143 ,\n",
       "        0.38164318, -0.04771839,  0.04066481,  0.00811822, -0.42805856,\n",
       "        0.22001137,  0.23759991, -0.20571813, -0.5602594 ,  0.32658356,\n",
       "       -0.15547638,  0.02572181,  0.01439825,  0.18594338, -0.42304528,\n",
       "        0.0736827 ,  0.18465935,  0.19353278, -0.3225897 ,  0.6101388 ,\n",
       "       -0.05295844,  0.10941473,  0.4140978 , -0.0387166 ,  0.3852153 ,\n",
       "        0.2425858 , -0.22342841,  0.12341694, -0.3125555 , -0.06991664,\n",
       "       -0.71352977, -0.20803837, -0.392651  ,  0.6866755 , -0.34385532,\n",
       "        0.08384481,  0.48416698,  0.33665645,  0.41973245,  0.11085712,\n",
       "        0.5366151 ,  0.2705232 ,  0.34092292, -0.0194401 ,  0.7414495 ,\n",
       "        0.23238179,  0.37167567, -0.24040116,  0.1902005 ,  0.2266516 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert first review to vector\n",
    "print(df['review'][1]); print()\n",
    "document_vector(df['review'].values[1])\n",
    "# one review will be of size vector(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "596e9f75-abbb-494e-bcbe-8664c2b665d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\kumar\\anaconda3\\envs\\nlpenv\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kumar\\anaconda3\\envs\\nlpenv\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fee799d-1b70-4808-a7da-85be500de943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 9983/9983 [05:57<00:00, 27.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9983, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert all review to vector\n",
    "from tqdm import tqdm\n",
    "X = []\n",
    "for doc in tqdm(df['review'].values):\n",
    "    X.append(document_vector(doc))\n",
    "\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a815b34-aaad-49a8-8750-a5bd59c12324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now convert y to vector using labelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df['sentiment'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d806e802-cc28-4756-abaa-e4cfc7476e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32e4000f-fcc6-4378-835c-04b49d8ef96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.61942914371556"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "#accuracy\n",
    "accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "268c9644-56a6-4319-ab59-220fa9a864ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one    reviewers  mentioned   watching  1 oz e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production  filming techniqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought    wonderful way  spend time    hot s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres  family   little boy jake thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love   time  money   visually s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>fun entertaining movie  wwii german spy julie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>give   break   anyone say     good hockey movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>movie   bad movie   watching  endless series ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>movie   probably made  entertain  middle sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>smashing film  filmmaking shows  intense  stra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9983 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review\n",
       "0     one    reviewers  mentioned   watching  1 oz e...\n",
       "1      wonderful little production  filming techniqu...\n",
       "2      thought    wonderful way  spend time    hot s...\n",
       "3     basically theres  family   little boy jake thi...\n",
       "4     petter matteis love   time  money   visually s...\n",
       "...                                                 ...\n",
       "9995  fun entertaining movie  wwii german spy julie ...\n",
       "9996  give   break   anyone say     good hockey movi...\n",
       "9997   movie   bad movie   watching  endless series ...\n",
       "9998     movie   probably made  entertain  middle sc...\n",
       "9999  smashing film  filmmaking shows  intense  stra...\n",
       "\n",
       "[9983 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 0:1]\n",
    "y = df['sentiment']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e79cf951-b9e1-4e41-be38-b3e555833ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       positive\n",
       "1       positive\n",
       "2       positive\n",
       "3       negative\n",
       "4       positive\n",
       "          ...   \n",
       "9995    positive\n",
       "9996    negative\n",
       "9997    negative\n",
       "9998    negative\n",
       "9999    positive\n",
       "Name: sentiment, Length: 9983, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50142653-4a53-4814-892d-5bc161a2c059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encoding on df['sentiment'] convert into 1 or 0\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffc9562d-33e9-4910-9abe-c7ea20b8e669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7986, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613a63c-666f-4ecc-8fb7-c81990c77df3",
   "metadata": {},
   "source": [
    "### Use BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4804b57c-6ca8-4233-9200-f7dbce8c385d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7986, 72190)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying BoW\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X_train_bow = cv.fit_transform(X_train['review']).toarray()\n",
    "X_test_bow = cv.transform(X_test['review']).toarray()\n",
    "X_train_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd234f-2c19-4471-a6b5-5e697f3727eb",
   "metadata": {},
   "source": [
    "X_train_bow.shape = (7986, 72190)  >---------> (no of rows, no. of word in vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7353028f-ed9e-4d85-ab4f-37be8f32c831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.59389083625438"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use gaussian naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_bow, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test_bow)\n",
    "# accuracy\n",
    "accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdca197f-7a6b-4c85-b9c1-30ad5b19cbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[672, 313],\n",
       "       [434, 578]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d1757-f9ca-44a7-9b8d-d9d1a7e6aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_bow, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test_bow)\n",
    "#accuracy\n",
    "accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63849176-3ab9-404d-8260-883b00bf573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc08ad5-7af4-475d-ad44-1ccc8ed213e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# few things to improve accuracy\n",
    "# take only 5000 words from vocab\n",
    "cv = CountVectorizer(max_features=5000)\n",
    "\n",
    "X_train_bow = cv.fit_transform(X_train['review']).toarray()\n",
    "X_test_bow = cv.transform(X_test['review']).toarray()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_bow, y_train)\n",
    "y_pred = rf.predict(X_test_bow)\n",
    "accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b835c0eb-2f5f-43cf-b88c-e9c6a2098e45",
   "metadata": {},
   "source": [
    "### Use n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012c6cb-eb5d-45b9-96b1-df9692a7eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use n-gram\n",
    "cv = CountVectorizer(ngram_range=(1, 3), max_features=50000)\n",
    "\n",
    "X_train_ngram = cv.fit_transform(X_train['review']).toarray()\n",
    "X_test_ngram = cv.transform(X_test['review']).toarray()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_ngram, y_train)\n",
    "y_pred = rf.predict(X_test_ngram)\n",
    "\n",
    "# accuracy\n",
    "accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1569c514-2251-42cd-85aa-8dc17c936b30",
   "metadata": {},
   "source": [
    "### Use TF-IDF\n",
    "- Use for Information Retrival System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f0e84-8d22-4801-9c52-5160756d4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train['review']).toarray()\n",
    "X_test_tfidf = tfidf.transform(X_test['review']).toarray()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "y_pred = rf.predict(X_train_tfidf)\n",
    "\n",
    "# accuracy\n",
    "accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d35215-0c21-4df3-b6ba-18dec668ea0f",
   "metadata": {},
   "source": [
    "### **Use Word2Vec**\n",
    "- 1. Use Pre-trained Word2Vec\n",
    "  2. Train Your Word2Vec on Your Data (Make sure you have sufficient data)\n",
    "- Sentence >---> `avg word2vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1a1dd3-f26f-468e-8cc3-d10a77830b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6611c875-ea00-4870-93ba-38bf3f36dff4",
   "metadata": {},
   "source": [
    "### **Practical Advice**\n",
    "- Use enssemble technique\n",
    "- Use Heuristic Features\n",
    "- Do not use imbalance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b87bb4-c9f1-4d8e-b396-d6b41330d46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
