{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "481d504b-989f-4bc9-9346-5203149897b0",
   "metadata": {},
   "source": [
    "## <b style=\"color:green\">Word2Vec</b>\n",
    "- ### <b style=\"color:red\">Word Embeddings</b>\n",
    "  - In natural language processing, word embedding is a term used for the representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning.\n",
    "- ### <b style=\"color:red\">Types of Word Embedding</b>\n",
    "  1. __Frequency Based__\n",
    "     - Bag of Word\n",
    "     - TF-IDF\n",
    "     - Glove : Global Vector (Matrix Factorization)\n",
    "  2. __Prediction Based__\n",
    "     - Word2Vec "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a9d3f-556c-42b6-b6d0-2417b17efa49",
   "metadata": {},
   "source": [
    "### <b style=\"color:blue\">Word2Vec</b>\n",
    "- Created by Google in 2013.\n",
    "- It is a word embedding technique. Given word convert into collection of vector.\n",
    "- **Advantage :**\n",
    "  - You can find the semantic meaning of words. eg : happy == joy\n",
    "  - Dimension of vector will be smaller than other vectorization techniques. Dense Vector.\n",
    "  - Low sparsity, no overfitting.\n",
    "- Deep learning technique.\n",
    "- Two way for Word2Vec\n",
    "  1. Pre-trained Model\n",
    "  2. Self- Trained\n",
    "- **Pre-Trained Model :**  \\\n",
    "  We will use the pre-trained weights of `word2vec` that was trained on __Google News__ Corpus containing 3 billion words. This model consists of 300-dimensional vectors for 3 million words and phrases.  \\\n",
    "  We use `gensim` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deca16c2-a10d-4fea-9572-8add186dcbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7427954-6299-4b1b-8ced-a4936e412737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\kumar\\anaconda3\\envs\\nlpenv\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4d217e-9095-436d-8c53-8702ca89770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Download the Word2Vec model\n",
    "model = api.load(\"word2vec-google-news-300\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649e0bd4-20a4-43a9-9c00-bb525bcc35e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['man'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ad040a1-3ae7-4082-ab22-addb62152b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32617188,  0.13085938,  0.03466797, -0.08300781,  0.08984375,\n",
       "       -0.04125977, -0.19824219,  0.00689697,  0.14355469,  0.0019455 ,\n",
       "        0.02880859, -0.25      , -0.08398438, -0.15136719, -0.10205078,\n",
       "        0.04077148, -0.09765625,  0.05932617,  0.02978516, -0.10058594,\n",
       "       -0.13085938,  0.001297  ,  0.02612305, -0.27148438,  0.06396484,\n",
       "       -0.19140625, -0.078125  ,  0.25976562,  0.375     , -0.04541016,\n",
       "        0.16210938,  0.13671875, -0.06396484, -0.02062988, -0.09667969,\n",
       "        0.25390625,  0.24804688, -0.12695312,  0.07177734,  0.3203125 ,\n",
       "        0.03149414, -0.03857422,  0.21191406, -0.00811768,  0.22265625,\n",
       "       -0.13476562, -0.07617188,  0.01049805, -0.05175781,  0.03808594,\n",
       "       -0.13378906,  0.125     ,  0.0559082 , -0.18261719,  0.08154297,\n",
       "       -0.08447266, -0.07763672, -0.04345703,  0.08105469, -0.01092529,\n",
       "        0.17480469,  0.30664062, -0.04321289, -0.01416016,  0.09082031,\n",
       "       -0.00927734, -0.03442383, -0.11523438,  0.12451172, -0.0246582 ,\n",
       "        0.08544922,  0.14355469, -0.27734375,  0.03662109, -0.11035156,\n",
       "        0.13085938, -0.01721191, -0.08056641, -0.00708008, -0.02954102,\n",
       "        0.30078125, -0.09033203,  0.03149414, -0.18652344, -0.11181641,\n",
       "        0.10253906, -0.25976562, -0.02209473,  0.16796875, -0.05322266,\n",
       "       -0.14550781, -0.01049805, -0.03039551, -0.03857422,  0.11523438,\n",
       "       -0.0062561 , -0.13964844,  0.08007812,  0.06103516, -0.15332031,\n",
       "       -0.11132812, -0.14160156,  0.19824219, -0.06933594,  0.29296875,\n",
       "       -0.16015625,  0.20898438,  0.00041771,  0.01831055, -0.20214844,\n",
       "        0.04760742,  0.05810547, -0.0123291 , -0.01989746, -0.00364685,\n",
       "       -0.0135498 , -0.08251953, -0.03149414,  0.00717163,  0.20117188,\n",
       "        0.08300781, -0.0480957 , -0.26367188, -0.09667969, -0.22558594,\n",
       "       -0.09667969,  0.06494141, -0.02502441,  0.08496094,  0.03198242,\n",
       "       -0.07568359, -0.25390625, -0.11669922, -0.01446533, -0.16015625,\n",
       "       -0.00701904, -0.05712891,  0.02807617, -0.09179688,  0.25195312,\n",
       "        0.24121094,  0.06640625,  0.12988281,  0.17089844, -0.13671875,\n",
       "        0.1875    , -0.10009766, -0.04199219, -0.12011719,  0.00524902,\n",
       "        0.15625   , -0.203125  , -0.07128906, -0.06103516,  0.01635742,\n",
       "        0.18261719,  0.03588867, -0.04248047,  0.16796875, -0.15039062,\n",
       "       -0.16992188,  0.01831055,  0.27734375, -0.01269531, -0.0390625 ,\n",
       "       -0.15429688,  0.18457031, -0.07910156,  0.09033203, -0.02709961,\n",
       "        0.08251953,  0.06738281, -0.16113281, -0.19628906, -0.15234375,\n",
       "       -0.04711914,  0.04760742,  0.05908203, -0.16894531, -0.14941406,\n",
       "        0.12988281,  0.04321289,  0.02624512, -0.1796875 , -0.19628906,\n",
       "        0.06445312,  0.08935547,  0.1640625 , -0.03808594, -0.09814453,\n",
       "       -0.01483154,  0.1875    ,  0.12792969,  0.22753906,  0.01818848,\n",
       "       -0.07958984, -0.11376953, -0.06933594, -0.15527344, -0.08105469,\n",
       "       -0.09277344, -0.11328125, -0.15136719, -0.08007812, -0.05126953,\n",
       "       -0.15332031,  0.11669922,  0.06835938,  0.0324707 , -0.33984375,\n",
       "       -0.08154297, -0.08349609,  0.04003906,  0.04907227, -0.24121094,\n",
       "       -0.13476562, -0.05932617,  0.12158203, -0.34179688,  0.16503906,\n",
       "        0.06176758, -0.18164062,  0.20117188, -0.07714844,  0.1640625 ,\n",
       "        0.00402832,  0.30273438, -0.10009766, -0.13671875, -0.05957031,\n",
       "        0.0625    , -0.21289062, -0.06542969,  0.1796875 , -0.07763672,\n",
       "       -0.01928711, -0.15039062, -0.00106049,  0.03417969,  0.03344727,\n",
       "        0.19335938,  0.01965332, -0.19921875, -0.10644531,  0.01525879,\n",
       "        0.00927734,  0.01416016, -0.02392578,  0.05883789,  0.02368164,\n",
       "        0.125     ,  0.04760742, -0.05566406,  0.11572266,  0.14746094,\n",
       "        0.1015625 , -0.07128906, -0.07714844, -0.12597656,  0.0291748 ,\n",
       "        0.09521484, -0.12402344, -0.109375  , -0.12890625,  0.16308594,\n",
       "        0.28320312, -0.03149414,  0.12304688, -0.23242188, -0.09375   ,\n",
       "       -0.12988281,  0.0135498 , -0.03881836, -0.08251953,  0.00897217,\n",
       "        0.16308594,  0.10546875, -0.13867188, -0.16503906, -0.03857422,\n",
       "        0.10839844, -0.10498047,  0.06396484,  0.38867188, -0.05981445,\n",
       "       -0.0612793 , -0.10449219, -0.16796875,  0.07177734,  0.13964844,\n",
       "        0.15527344, -0.03125   , -0.20214844, -0.12988281, -0.10058594,\n",
       "       -0.06396484, -0.08349609, -0.30273438, -0.08007812,  0.02099609],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "000c55da-7e50-4d66-b69f-d6f0b2699750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02941895,  0.11767578, -0.15039062,  0.00192261, -0.11230469,\n",
       "        0.30273438,  0.38476562, -0.2734375 ,  0.23828125,  0.29492188,\n",
       "       -0.08056641, -0.48242188,  0.05664062, -0.01623535, -0.31054688,\n",
       "        0.14941406, -0.16308594,  0.26757812,  0.09521484, -0.109375  ,\n",
       "        0.24414062,  0.09228516, -0.02404785, -0.15136719, -0.13769531,\n",
       "        0.18066406,  0.02270508,  0.26171875,  0.11230469,  0.12695312,\n",
       "        0.12060547, -0.00159454, -0.24511719,  0.04833984, -0.08935547,\n",
       "        0.00787354,  0.14257812, -0.04736328, -0.15039062, -0.00081253,\n",
       "       -0.33984375,  0.109375  ,  0.34570312, -0.11669922,  0.10253906,\n",
       "       -0.15234375, -0.02868652,  0.07324219,  0.11669922, -0.25390625,\n",
       "       -0.38867188, -0.10693359,  0.02441406, -0.31054688,  0.0534668 ,\n",
       "       -0.07275391,  0.14453125,  0.15332031, -0.06225586, -0.07177734,\n",
       "       -0.27929688,  0.05224609,  0.13964844, -0.02282715, -0.08642578,\n",
       "       -0.11572266,  0.05932617, -0.3359375 ,  0.34179688, -0.03344727,\n",
       "        0.06591797, -0.02514648,  0.39257812, -0.14257812, -0.37109375,\n",
       "        0.24902344, -0.03198242,  0.1953125 ,  0.23046875, -0.13476562,\n",
       "       -0.05932617, -0.296875  , -0.31640625, -0.1875    , -0.09179688,\n",
       "        0.10107422,  0.0559082 ,  0.16113281,  0.29492188,  0.07275391,\n",
       "       -0.13769531,  0.2734375 ,  0.06298828, -0.34765625, -0.25      ,\n",
       "        0.14160156,  0.02648926, -0.06005859,  0.09716797,  0.1640625 ,\n",
       "       -0.14355469, -0.07373047,  0.15625   ,  0.19335938,  0.06787109,\n",
       "       -0.3046875 ,  0.29492188,  0.02819824, -0.01965332, -0.14160156,\n",
       "        0.14746094, -0.109375  , -0.18066406, -0.22460938, -0.21484375,\n",
       "        0.03369141, -0.11816406, -0.17578125, -0.05737305, -0.05786133,\n",
       "       -0.13183594, -0.07226562, -0.02783203, -0.05859375,  0.02697754,\n",
       "       -0.08447266,  0.34179688, -0.16601562,  0.07910156,  0.04760742,\n",
       "       -0.23339844,  0.14257812, -0.30664062, -0.12402344, -0.0378418 ,\n",
       "        0.51171875,  0.328125  , -0.24316406,  0.07617188,  0.13574219,\n",
       "       -0.05493164, -0.25976562, -0.22363281, -0.19042969, -0.15527344,\n",
       "        0.13085938,  0.06738281,  0.03271484,  0.00549316, -0.32226562,\n",
       "        0.38671875,  0.18652344, -0.11572266,  0.00704956,  0.25390625,\n",
       "       -0.08105469, -0.22851562,  0.07421875,  0.01275635,  0.19140625,\n",
       "        0.00113678, -0.01623535,  0.08105469,  0.04638672,  0.078125  ,\n",
       "       -0.25976562,  0.2421875 ,  0.12695312, -0.2421875 , -0.12890625,\n",
       "       -0.15820312, -0.0859375 , -0.07177734,  0.22363281, -0.50390625,\n",
       "       -0.11914062,  0.13085938, -0.08203125, -0.43359375,  0.08349609,\n",
       "       -0.03344727,  0.08056641, -0.0177002 ,  0.125     , -0.2421875 ,\n",
       "        0.2109375 ,  0.00915527,  0.41015625, -0.203125  ,  0.11181641,\n",
       "       -0.18847656,  0.0625    , -0.02111816,  0.19726562, -0.12402344,\n",
       "        0.18847656, -0.03125   , -0.05371094, -0.140625  , -0.1796875 ,\n",
       "       -0.04467773,  0.04370117, -0.28710938,  0.13183594,  0.26171875,\n",
       "       -0.01409912, -0.08154297,  0.05932617,  0.03613281,  0.04833984,\n",
       "       -0.16992188, -0.11669922, -0.14746094,  0.19335938, -0.109375  ,\n",
       "        0.20898438, -0.23339844, -0.03930664,  0.01635742,  0.2578125 ,\n",
       "        0.02612305, -0.11376953, -0.0703125 ,  0.09863281,  0.23144531,\n",
       "        0.23535156,  0.15429688,  0.05078125, -0.02648926,  0.26171875,\n",
       "       -0.15429688,  0.02856445, -0.14453125, -0.11572266, -0.04858398,\n",
       "       -0.25585938, -0.25585938,  0.00056458,  0.21777344,  0.03564453,\n",
       "        0.07080078, -0.08007812,  0.06396484, -0.07861328,  0.2578125 ,\n",
       "        0.11767578, -0.32421875,  0.01116943, -0.14550781, -0.09667969,\n",
       "       -0.06201172,  0.0177002 ,  0.328125  ,  0.02490234,  0.03710938,\n",
       "        0.21386719,  0.00218201,  0.12451172,  0.02819824, -0.20410156,\n",
       "       -0.11962891,  0.0625    , -0.4375    ,  0.03320312,  0.00299072,\n",
       "       -0.16699219, -0.03466797, -0.13671875, -0.26757812,  0.14648438,\n",
       "       -0.18457031, -0.15429688, -0.1640625 ,  0.42773438,  0.25      ,\n",
       "        0.15429688, -0.06494141, -0.15332031, -0.03417969, -0.19921875,\n",
       "       -0.18945312,  0.11669922,  0.3046875 ,  0.08447266,  0.10058594,\n",
       "        0.0703125 , -0.11230469,  0.26757812,  0.01165771,  0.05151367,\n",
       "        0.21679688, -0.16113281, -0.10986328,  0.13085938, -0.10351562,\n",
       "       -0.390625  ,  0.14453125,  0.06079102, -0.07373047, -0.01989746],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['bottle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "221b107e-03a6-415b-8963-3b95ff0eb601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.67187500e-01, -1.21582031e-01,  2.85156250e-01,  8.15429688e-02,\n",
       "        3.19824219e-02, -3.19824219e-02,  1.34765625e-01, -2.73437500e-01,\n",
       "        9.46044922e-03, -1.07421875e-01,  2.48046875e-01, -6.05468750e-01,\n",
       "        5.02929688e-02,  2.98828125e-01,  9.57031250e-02,  1.39648438e-01,\n",
       "       -5.41992188e-02,  2.91015625e-01,  2.85156250e-01,  1.51367188e-01,\n",
       "       -2.89062500e-01, -3.46679688e-02,  1.81884766e-02, -3.92578125e-01,\n",
       "        2.46093750e-01,  2.51953125e-01, -9.86328125e-02,  3.22265625e-01,\n",
       "        4.49218750e-01, -1.36718750e-01, -2.34375000e-01,  4.12597656e-02,\n",
       "       -2.15820312e-01,  1.69921875e-01,  2.56347656e-02,  1.50146484e-02,\n",
       "       -3.75976562e-02,  6.95800781e-03,  4.00390625e-01,  2.09960938e-01,\n",
       "        1.17675781e-01, -4.19921875e-02,  2.34375000e-01,  2.03125000e-01,\n",
       "       -1.86523438e-01, -2.46093750e-01,  3.12500000e-01, -2.59765625e-01,\n",
       "       -1.06933594e-01,  1.04003906e-01, -1.79687500e-01,  5.71289062e-02,\n",
       "       -7.41577148e-03, -5.59082031e-02,  7.61718750e-02, -4.14062500e-01,\n",
       "       -3.65234375e-01, -3.35937500e-01, -1.54296875e-01, -2.39257812e-01,\n",
       "       -3.73046875e-01,  2.27355957e-03, -3.51562500e-01,  8.64257812e-02,\n",
       "        1.26953125e-01,  2.21679688e-01, -9.86328125e-02,  1.08886719e-01,\n",
       "        3.65234375e-01, -5.66406250e-02,  5.66406250e-02, -1.09375000e-01,\n",
       "       -1.66992188e-01, -4.54101562e-02, -2.00195312e-01, -1.22558594e-01,\n",
       "        1.31835938e-01, -1.31835938e-01,  1.03027344e-01, -3.41796875e-01,\n",
       "       -1.57226562e-01,  2.04101562e-01,  4.39453125e-02,  2.44140625e-01,\n",
       "       -3.19824219e-02,  3.20312500e-01, -4.41894531e-02,  1.08398438e-01,\n",
       "       -4.98046875e-02, -9.52148438e-03,  2.46093750e-01, -5.59082031e-02,\n",
       "        4.07714844e-02, -1.78222656e-02, -2.95410156e-02,  1.65039062e-01,\n",
       "        5.03906250e-01, -2.81250000e-01,  9.81445312e-02,  1.80664062e-02,\n",
       "       -1.83593750e-01,  2.53906250e-01,  2.25585938e-01,  1.63574219e-02,\n",
       "        1.81640625e-01,  1.38671875e-01,  3.33984375e-01,  1.39648438e-01,\n",
       "        1.45874023e-02, -2.89306641e-02, -8.39843750e-02,  1.50390625e-01,\n",
       "        1.67968750e-01,  2.28515625e-01,  3.59375000e-01,  1.22558594e-01,\n",
       "       -3.28125000e-01, -1.56250000e-01,  2.77343750e-01,  1.77001953e-02,\n",
       "       -1.46484375e-01, -4.51660156e-03, -4.46777344e-02,  1.75781250e-01,\n",
       "       -3.75000000e-01,  1.16699219e-01, -1.39648438e-01,  2.55859375e-01,\n",
       "       -1.96289062e-01, -2.57568359e-02, -5.41992188e-02, -2.51464844e-02,\n",
       "       -1.93359375e-01, -3.17382812e-02, -8.74023438e-02, -1.32812500e-01,\n",
       "       -2.12402344e-02,  4.33593750e-01, -5.20019531e-02,  3.46679688e-02,\n",
       "        8.00781250e-02,  3.41796875e-02,  1.99218750e-01, -2.39257812e-02,\n",
       "       -2.37304688e-01,  1.93359375e-01,  7.32421875e-02, -2.87109375e-01,\n",
       "        1.25000000e-01,  8.44726562e-02,  1.30859375e-01, -2.19726562e-01,\n",
       "       -1.61132812e-01, -2.63671875e-01, -5.46875000e-01, -2.96875000e-01,\n",
       "        3.44238281e-02, -2.87109375e-01, -1.93359375e-01, -1.61132812e-01,\n",
       "       -3.84765625e-01, -2.14843750e-01, -6.22558594e-03, -1.27929688e-01,\n",
       "       -1.00097656e-01, -6.21093750e-01,  3.78906250e-01, -4.58984375e-01,\n",
       "        1.44531250e-01, -9.13085938e-02, -3.08593750e-01,  2.23632812e-01,\n",
       "        7.86132812e-02, -2.16796875e-01,  8.78906250e-02, -1.66992188e-01,\n",
       "        1.14746094e-02, -2.53906250e-01, -6.25000000e-02,  6.04248047e-03,\n",
       "        1.56250000e-01,  4.37500000e-01, -2.23632812e-01, -2.32421875e-01,\n",
       "        2.75390625e-01,  2.39257812e-01,  4.49218750e-02, -7.51953125e-02,\n",
       "        5.74218750e-01, -2.61230469e-02, -1.21582031e-01,  2.44140625e-01,\n",
       "       -3.37890625e-01,  8.59375000e-02, -7.71484375e-02,  4.85839844e-02,\n",
       "        1.43554688e-01,  4.25781250e-01, -4.29687500e-02, -1.08398438e-01,\n",
       "        1.19628906e-01, -1.91406250e-01, -2.12890625e-01, -2.87109375e-01,\n",
       "       -1.14746094e-01, -2.04101562e-01, -2.06298828e-02, -2.53906250e-01,\n",
       "        8.25195312e-02, -3.97949219e-02, -1.57226562e-01,  1.34765625e-01,\n",
       "        2.08007812e-01, -1.78710938e-01, -2.00195312e-02, -8.34960938e-02,\n",
       "       -1.20605469e-01,  4.29687500e-02, -1.94335938e-01, -1.32812500e-01,\n",
       "       -2.17285156e-02, -2.35351562e-01, -3.63281250e-01,  1.51367188e-01,\n",
       "        9.32617188e-02,  1.63085938e-01,  1.02050781e-01, -4.27734375e-01,\n",
       "        2.83203125e-01,  2.74658203e-04, -3.20312500e-01,  1.68457031e-02,\n",
       "        4.06250000e-01, -5.24902344e-02,  7.91015625e-02, -1.41601562e-01,\n",
       "        5.27343750e-01, -1.26953125e-01,  4.74609375e-01, -6.64062500e-02,\n",
       "        3.41796875e-01, -1.78710938e-01,  3.69140625e-01, -2.05078125e-01,\n",
       "        5.82885742e-03, -1.84570312e-01, -8.88671875e-02, -1.81640625e-01,\n",
       "       -4.80957031e-02,  4.39453125e-01,  2.12890625e-01, -3.07617188e-02,\n",
       "        9.32617188e-02,  2.40234375e-01,  2.39257812e-01,  2.51953125e-01,\n",
       "       -1.98974609e-02,  1.24511719e-01, -4.73632812e-02, -2.13623047e-02,\n",
       "        3.12500000e-02,  3.05175781e-02,  2.79296875e-01,  9.08203125e-02,\n",
       "       -2.02148438e-01, -2.19726562e-02, -2.63671875e-01,  8.78906250e-02,\n",
       "       -1.07421875e-01, -2.49023438e-01, -1.22070312e-02,  1.73828125e-01,\n",
       "       -9.91210938e-02,  7.27539062e-02,  2.59765625e-01, -4.60937500e-01,\n",
       "        3.59375000e-01, -2.25585938e-01,  1.87988281e-02, -2.19726562e-01,\n",
       "       -2.08984375e-01, -1.51367188e-01,  8.64257812e-02,  1.11694336e-02,\n",
       "        6.93359375e-02, -2.99072266e-02,  1.43554688e-01,  1.89453125e-01,\n",
       "       -1.32812500e-01,  4.72656250e-01, -1.40625000e-01, -2.52685547e-02,\n",
       "        1.91406250e-01, -2.63671875e-01, -1.39648438e-01,  1.09375000e-01,\n",
       "        1.97753906e-02,  2.49023438e-01, -1.42578125e-01,  4.15039062e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector representation of cricket word in 300 dimension\n",
    "model['cricket']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed73e2bd-06c9-4c98-947c-659fcbf28eba",
   "metadata": {},
   "source": [
    "- 3.19824219e-02 >--->> Vector >--->>> 30 Lakh words >--->>> vector representation >--->>> each vector construct using 300 numbers >--->>> dimension of each word in 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9afdb0b8-6ef9-4471-bbe9-a495db86263f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.7664011716842651),\n",
       " ('boy', 0.6824870109558105),\n",
       " ('teenager', 0.6586930155754089),\n",
       " ('teenage_girl', 0.6147903203964233),\n",
       " ('girl', 0.5921714305877686),\n",
       " ('suspected_purse_snatcher', 0.571636438369751),\n",
       " ('robber', 0.5585119128227234),\n",
       " ('Robbery_suspect', 0.5584409832954407),\n",
       " ('teen_ager', 0.5549196600914001),\n",
       " ('men', 0.5489763021469116)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar words to the man in dataset\n",
    "model.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5625a51a-3ca2-46e8-a268-6ad303ae8e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cricketing', 0.8372224569320679),\n",
       " ('cricketers', 0.8165745735168457),\n",
       " ('Test_cricket', 0.8094818592071533),\n",
       " ('Twenty##_cricket', 0.8068488240242004),\n",
       " ('Twenty##', 0.7624266147613525),\n",
       " ('Cricket', 0.75413978099823),\n",
       " ('cricketer', 0.7372578382492065),\n",
       " ('twenty##', 0.7316356301307678),\n",
       " ('T##_cricket', 0.7304613590240479),\n",
       " ('West_Indies_cricket', 0.6987985968589783)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('cricket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc44c820-4abd-4572-9709-b084b1e2ed7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Facebook', 0.7563533186912537),\n",
       " ('FaceBook', 0.7076998949050903),\n",
       " ('twitter', 0.6988552212715149),\n",
       " ('myspace', 0.6941817998886108),\n",
       " ('Twitter', 0.664244532585144),\n",
       " ('twitter_facebook', 0.6572229266166687),\n",
       " ('Facebook.com', 0.6529868841171265),\n",
       " ('myspace_facebook', 0.6370643973350525),\n",
       " ('facebook_twitter', 0.6367618441581726),\n",
       " ('linkedin', 0.6356593370437622)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('facebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eb6343f-584e-4856-b816-841ecf3a405e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2883053"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how much both word are similar to each other >--->>> cos(theta)\n",
    "model.similarity('man', 'women')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "941ba3eb-ebef-4d2d-a1c9-ec21b47c2ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'java'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get odd one\n",
    "model.doesnt_match(['python', 'java', 'monkey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fec5d0d-4542-4b08-a62b-e2ce2da1fa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'monkey'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get odd one\n",
    "model.doesnt_match(['c++', 'java', 'php', 'monkey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ff04c2-f74a-4c87-a1b3-2160298896a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.6478991508483887),\n",
       " ('queen', 0.5354938507080078),\n",
       " ('women', 0.52336585521698),\n",
       " ('kings', 0.5162314176559448),\n",
       " ('queens', 0.499536395072937),\n",
       " ('kumaris', 0.4923847019672394),\n",
       " ('princes', 0.46233269572257996),\n",
       " ('monarch', 0.45280295610427856),\n",
       " ('monarchy', 0.4293173551559448),\n",
       " ('kings_princes', 0.42342403531074524)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arithematic operation with words\n",
    "vec = model['king'] - model['man'] + model['women']\n",
    "model.most_similar([vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "295dc5fe-88ed-4d6c-ba14-e658c69dfead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('INR', 0.6442340612411499),\n",
       " ('GBP', 0.5040826797485352),\n",
       " ('£_##.###m', 0.45408377051353455),\n",
       " ('England', 0.44649267196655273),\n",
       " ('£', 0.43341001868247986),\n",
       " ('Â_£', 0.4307198226451874),\n",
       " ('stg###', 0.4299262464046478),\n",
       " ('£_#.##m', 0.42561304569244385),\n",
       " ('Pounds_Sterling', 0.42512622475624084),\n",
       " ('GBP##', 0.42464494705200195)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['INR'] - model['India'] + model['England']\n",
    "model.most_similar([vec])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d66cdb-6548-4fad-825c-587f3bd93000",
   "metadata": {},
   "source": [
    "### <b style=\"color:blue\">Intution</b>\n",
    "- Words : King, Queen, Man, Women, Monkey   \\\n",
    "  Features : gender, wealth, power, weight, speak   \\\n",
    "  Features decides by programmer.  \n",
    "  <pre>\n",
    "    ______________________________________________________________ \n",
    "    | <b>features</b> |  King  |  Queen  |   Man   |  Women  |  Monkey  |\n",
    "    |__________|________|_________|_________|_________|__________|\n",
    "    | gender   |   1    |    0    |    1    |    0    |    1     |\n",
    "    |__________|________|_________|_________|_________|__________|\n",
    "    | wealth   |   1    |    1    |   0.3   |   0.3   |    0     |\n",
    "    |__________|________|_________|_________|_________|__________|\n",
    "    | power    |   1    |   0.7   |   0.2   |   0.2   |    0     |\n",
    "    |__________|________|_________|_________|_________|__________|\n",
    "    | weight   |  0.8   |   0.4   |   0.6   |   0.5   |   0.3    |\n",
    "    |__________|________|_________|_________|_________|__________|\n",
    "    | speak    |   1    |    1    |    1    |    1    |    0     |\n",
    "    |__________|________|_________|_________|_________|__________|\n",
    "  </pre>   \n",
    "- King = [1, 1, 1, 0.8, 1]   \\\n",
    "  Monkey = [1, 0, 0, 0.3, 0]  \\\n",
    "  Man = [1, 0.3, 0.2, 0.6, 1]\n",
    "- King - Man + Women   \n",
    "  <pre>\n",
    "      _____________________________________________\n",
    "      |           |  King - Man + Women |    =    |          \n",
    "      |___________|_____________________|_________|\n",
    "      |  gender   |    1 - 1 + 0        |    0    |\n",
    "      |___________|_____________________|_________|\n",
    "      |  wealth   |    1 - 0.3 + 0.3    |    1    |\n",
    "      |___________|_____________________|_________|\n",
    "      |  power    |    1 - 0.2 + 0.2    |    1    |\n",
    "      |___________|_____________________|_________|\n",
    "      |  weight   |    0.8 - 0.6 + 0.5  |   0.7   |\n",
    "      |___________|_____________________|_________|\n",
    "      |  speak    |    1 - 1 + 1        |    1    |\n",
    "      |___________|_____________________|_________|   \n",
    "  </pre>  \n",
    "  Queen = [0, 1, 0.7, 0.4, 1]   \\\n",
    "  King - Man + Women = [0, 1, 1, 0.7, 1]   \\\n",
    "  3 Similar and 2 unsimilar\n",
    "- We use __Nural Network__ to create the __Features__.  \\\n",
    "  Feature will not be like _'gender'_, _'power'_ and _'speak'_ but it will be like _'f1'_, _'f2'_, _'f2'_ etc.\n",
    "- How the features are decided.  \\\n",
    "  The underlying assmption of `Word2Vec` is that two words sharing similar contexts also share a similar meaning and consequently a similar vector representation from the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f04139-78a3-4bc2-b43a-089a088f1774",
   "metadata": {},
   "source": [
    "### <b style=\"color:blue\">Types of Word2Vec</b>\n",
    "1. __CBow__ : Continuous Bag of Word\n",
    "2. __Strip-gram__\n",
    "- Both are Neural Network. Shallow neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2389df86-8644-4789-9ada-f177c4e4ce91",
   "metadata": {},
   "source": [
    "### **CBow** : Continuous Bag of Word\n",
    "- Dummy(Fake) Problem >---> Solve >---> Get Vector in Byproduct\n",
    "- Convert every word to OHE.\n",
    "- Decide the window size.\n",
    "- Example : \\\n",
    "  statement = watch campusx for data science     \\\n",
    "  corpus = [watch, campusx, for, data, science]  \\\n",
    "  vocabulary = [watch, campusx, for, data, science] \n",
    "  <pre>\n",
    "      <b>OHE</b> = watch : [1,0,0,0,0]\n",
    "            campusx : [0,1,0,0,0]\n",
    "            for : [0,0,1,0,0]\n",
    "            data : [0,0,0,1,0]\n",
    "            science : [0,0,0,0,1]\n",
    "      <b>Size of Window</b> = 3, stride = 1\n",
    "         [watch campusx for]\n",
    "      <b>context word</b> = watch, for\n",
    "      <b>target word</b> = campusx\n",
    "      <b>Training Data : </b>\n",
    "                          _______________________________\n",
    "                         |      X          |      Y      |\n",
    "                         |_________________|_____________|\n",
    "                         |  watch, for     |  campusx    |\n",
    "                         |_________________|_____________|\n",
    "                         |  campusx, data  |     for     |\n",
    "                         |_________________|_____________|\n",
    "                         |  for, science   |     data    |\n",
    "                         |_________________|_____________|\n",
    "\n",
    "                          _____________________________________________________________\n",
    "                         |                  X                    |          Y          |\n",
    "                         |_______________________________________|_____________________|\n",
    "                         | watch[1,0,0,0,0], for[0,0,1,0,0]      | campusx[0,1,0,0,0]  |\n",
    "                         |_______________________________________|_____________________|\n",
    "                         |  campusx[0,1,0,0,0], data[0,0,0,1,0]  |     for[0,0,1,0,0]  |\n",
    "                         |_______________________________________|_____________________|\n",
    "                         |  for[0,0,1,0,0], science[0,0,0,0,1]   |     data[0,0,0,1,0] |\n",
    "                         |_______________________________________|_____________________|\n",
    "  </pre>\n",
    "- Architechture of __CBow__. \n",
    "  <pre>\n",
    "      context\n",
    "        ___\n",
    "    w1 |___|\n",
    "    w2 |___| watch [1,0,0,0,0]\n",
    "    w3 |___|\\\n",
    "    w4 |___| \\                        target  \n",
    "    w5 |___|  \\       window              ___\n",
    "             w \\ b     ___               |___|\n",
    "          (5x3) \\   w1|___|  w, b (3x5)  |___| predicted [0, 0.3, 0.1, 0, 0] >----->>> Calculate Loss\n",
    "                 \\  w2|___| -----------> |___| campusx [0, 1, 0, 0, 0]\n",
    "                 /  w3|___|  embedding   |___| \n",
    "                /                        |___|\n",
    "        ___    /\n",
    "    w1 |___|  /  w, b (5x3)\n",
    "    w2 |___| /\n",
    "    w3 |___|/\n",
    "    w4 |___| for [0,0,1,0,0]\n",
    "    w5 |___|\n",
    "   >-------------------forward propagation--------------------->\n",
    "   <---------------------back propagation----------------------<\n",
    "  </pre>\n",
    "- Vector representation of any word like `watch = [w1, w2, w3]` at the position of embedding.\n",
    "- It is a fully connected nural netwok.\n",
    "- For starting take random w(weight).\n",
    "- Calculate the __Loss__ and do ___backpropagation___ and ___forward propagation___ with new updated w(weight).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c694d5c-d2cd-47eb-b5b8-c7256afaffb0",
   "metadata": {},
   "source": [
    "### **Skip-gram**\n",
    "- Statement = watch campusx for data science\n",
    "- Convert every word to OHE.\n",
    "- Decide the window size.\n",
    "- Example : \\\n",
    "  statement = watch campusx for data science      \\\n",
    "  corpus = [watch, campusx, for, data, science]   \\\n",
    "  vocabulary = [watch, campusx, for, data, science] \n",
    "  <pre>\n",
    "      <b>OHE</b> = watch : [1,0,0,0,0]\n",
    "            campusx : [0,1,0,0,0]\n",
    "            for : [0,0,1,0,0]\n",
    "            data : [0,0,0,1,0]\n",
    "            science : [0,0,0,0,1]\n",
    "      <b>Size of Window</b> = 3, stride = 1\n",
    "         [watch campusx for]\n",
    "      <b>context word</b> = campusx\n",
    "      <b>target word</b> = watch, for\n",
    "      <b>Dataset : </b>\n",
    "      <b>Training Data : </b>\n",
    "                          ______________________________________________________________\n",
    "                         |           X          |                   Y                   |\n",
    "                         |______________________|_______________________________________|\n",
    "                         |  campusx[0,1,0,0,0]  |   watch[1,0,0,0,0], for[0,0,1,0,0]    |\n",
    "                         |______________________|_______________________________________|\n",
    "                         |    for[0,0,1,0,0]    |  campusx[0,1,0,0,0], data[0,0,0,1,0]  |\n",
    "                         |______________________|_______________________________________|\n",
    "                         |    data[0,0,0,1,0]   |  for[0,0,1,0,0], science[0,0,0,0,1]   |\n",
    "                         |______________________|_______________________________________|\n",
    "  </pre>\n",
    "- Architecture of __skip-ngram__.\n",
    "  <pre>\n",
    "                                         ___\n",
    "                                        |___|  \n",
    "                                      / |___|\n",
    "                               w, b  /  |___|   predicted >---> Calculate Loss >---> update w(weight)\n",
    "      context                 (3x5) /   |___|\n",
    "        ___             embedding  /    |___|\n",
    "    w1 |___|                ___   /\n",
    "    w2 |___|  w, b (5x3) w1|___| /\n",
    "    w3 |___| ----------> w2|___| \\  \n",
    "    w4 |___|             w3|___|  \\      ___\n",
    "    w5 |___|                       \\    |___|\n",
    "                              w, b  \\   |___|\n",
    "                              (3x5)  \\  |___|   predicted >---> Calculate Loss  >---> update w(weight)\n",
    "                                      \\ |___|\n",
    "                                        |___|\n",
    "\n",
    "    >---------------------------forward propagation--------------------------------->\n",
    "    <-----------------------------back propagation----------------------------------<\n",
    "  </pre>\n",
    "- Vector representation of any word like `watch = [w1, w2, w3]` at the position of embedding.\n",
    "- It is a fully connected nural netwok.\n",
    "- For starting take random w(weight).\n",
    "- Calculate the __Loss__ and do ___backpropagation___ and ___forward propagation___ with new updated w(weight).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60f4d00-a7b0-49ab-8c19-17cc6048384c",
   "metadata": {},
   "source": [
    "### When to use what?\n",
    "- It is research prooven that.\n",
    "- Use CBow for small dataset. It is fast and give accurate result with small dataset.\n",
    "- Use Skip-gram for big dataset.\n",
    "- Word2Vec to impove quality by :\n",
    "  - Increase training data.\n",
    "  - Increase the dimension of hidden layer.\n",
    "  - Increase the window size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc8aa2-c0ea-46ed-8bc2-ef20d5d1111d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
