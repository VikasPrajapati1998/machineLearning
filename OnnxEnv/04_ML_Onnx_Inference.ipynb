{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7b3388-0df1-42d3-b22d-3fd0f8132bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a780796f-3d78-4400-bb56-10f212605876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :  [2 1 2]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[4.5, 4.9, 5.1, 5.4],\n",
    "                 [1.5, 2.9, 3.1, 1.4],\n",
    "                 [7.5, 6.9, 8.1, 6.4]])\n",
    "\n",
    "sess = ort.InferenceSession('output/model.onnx')\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "\n",
    "pred_onnx = sess.run([label_name], {input_name : data.astype(np.float32)})[0]\n",
    "print(\"Prediction : \", pred_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f80326-6450-488a-b130-602c9d0c0cb3",
   "metadata": {},
   "source": [
    "## **ONNX Runtime**\n",
    "- High performance inference engine for ONNX.\n",
    "- Founded and open sourced by Microsoft under MIT license\n",
    "- Full ONNX spec support (v1.2+)\n",
    "- Extensible and modular framework.\n",
    "- Ships with windows10 as WinML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699e108c-1891-4946-9a90-4896b844b430",
   "metadata": {},
   "source": [
    "<pre>\n",
    "     _________________________________________________________________________________________________________\n",
    "    |                  |                  |                |                |               |      CNTK       |\n",
    "    |    TensorFlow    |      PyTorch     |     Caffe2     |     Chainer    |     MXNet     |                 |\n",
    "    |__________________|__________________|________________|________________|_______________|_________________|\n",
    "\n",
    "     _________________________________________________________________________________________________________\n",
    "    |                                                                                                         |\n",
    "    |                                                    ONNX                                                 |\n",
    "    |_________________________________________________________________________________________________________|\n",
    "\n",
    "     _________________________________________________________________________________________________________\n",
    "    |                                                                                                         |\n",
    "    |                                                ONNX Runtime                                             |\n",
    "    |_________________________________________________________________________________________________________|\n",
    "          ||                      ||                     ||                    ||                      ||\n",
    "         \\||/                    \\||/                   \\||/                  \\||/                    \\||/\n",
    "     ___________              ___________            ____________           _________              ___________\n",
    "    |           |            |           |          |            |         |         |            |           |                               \n",
    "    |    CPU    |            |    GPU    |          |    FPGA    |         |   VPU   |            |    TPU    | \n",
    "    |___________|            |___________|          |____________|         |_________|            |___________|\n",
    "\n",
    "    \n",
    "    \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c5ffe-ef39-4157-967b-21c82d5457c1",
   "metadata": {},
   "source": [
    "## **ONNX Model Zoo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880cdf27-27f3-4f15-9981-66a428399e75",
   "metadata": {},
   "source": [
    "- There are a lot of pre-trained onnx model present in `Onnx Model Zoo`. You can download it and use it.\n",
    "- Step to use Onnx Model Zoo\n",
    "  - Create a environment\n",
    "  - Install numpy, onnx, onnxruntime, opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d0b55-a3bf-4b17-bec6-0f5812f05653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f32838-3609-4d9f-b9d0-ee80021b13ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
